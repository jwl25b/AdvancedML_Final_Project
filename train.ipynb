{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0140dc6-4050-48ed-bd27-aa8b2018440e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataloader_utils import get_conbined_permute_mnist, get_conbined_split_mnist, get_conbined_splitted_and_shuffled_mnist\n",
    "from autoencoder import Autoencoder\n",
    "from autoencoder_utils import * \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca8acda0-a5a5-498c-a040-b2ec03bf9ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a simple CNN and MLP using PyTorch\n",
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, outdim):\n",
    "        super(SmallCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(1024, 128)  # Adjust the input size based on your data\n",
    "        self.fc2 = nn.Linear(128, outdim)    # Output size depends on the number of classes\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape((x.shape[0], 1, 28, 28))\n",
    "        x = torch.relu(torch.max_pool2d(self.conv1(x), 2))\n",
    "        x = torch.relu(torch.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 1024)  # Flatten the tensor\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, outdim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, outdim)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)  # Flatten the image to a vector\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c5739fe-a53c-4055-bcd9-548f5091ad67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_loader, expert_outdim):\n",
    "    auto_list = {}\n",
    "    expert_list = {}\n",
    "    #debug\n",
    "    record = {}\n",
    "\n",
    "    #https://stats.stackexchange.com/questions/521461/train-a-model-on-batches-with-multiple-epochs-vs-each-batch-with-multiple-epoch\n",
    "    \n",
    "    #for i, data in enumerate(train_loader):\n",
    "    for i, data in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        \n",
    "        images, labels, indicies = data\n",
    "        \n",
    "       \n",
    "        ###debug###\n",
    "        #print(labels)\n",
    "        #show_image = images[0].cpu().detach().numpy().reshape((28,28))\n",
    "        #plt.imshow(show_image) # Plot the 28x28 image\n",
    "        #plt.show()\n",
    "        ###########\n",
    "        \n",
    "        #initial\n",
    "        if len(auto_list)==0:\n",
    "            \n",
    "            ###debug###\n",
    "            print(f\"[@ batch {i}] NEW autoencoder at {len(auto_list)} for Task {indicies[0].item()}\")\n",
    "            record[indicies[0].item()] = BATCH_SIZE\n",
    "            ###########\n",
    "            \n",
    "            #initial autoencoder\n",
    "            new_autoencoder = Autoencoder(input_dims=28*28, code_dims=CODE_DIM)\n",
    "            for epoch in range(NEW_AUTOENCODER_EPOCH):\n",
    "                new_autoencoder.optimize_params(images, images)\n",
    "            auto_list[len(auto_list)] = new_autoencoder\n",
    "\n",
    "            #initial expert\n",
    "            model = MLP(expert_outdim)\n",
    "            #model = SmallCNN(expert_outdim)\n",
    "            for _ in range(10):\n",
    "                model.optimizer.zero_grad()\n",
    "                predicted_output = model(images)\n",
    "                fit = model.loss(predicted_output, labels)\n",
    "                fit.backward()\n",
    "                model.optimizer.step()\n",
    "            expert_list[len(auto_list)-1] = model\n",
    "            continue\n",
    "\n",
    "        #find best autoencoder\n",
    "        best_index = find_best_autoencoders(images, auto_list)\n",
    "        best_autoencoder = auto_list[best_index]\n",
    "\n",
    "\n",
    "        #calculate outliers\n",
    "        outliers = find_num_of_outliers(images, best_autoencoder)\n",
    "        #print(f\"[@ batch {i}] outliers for best autoencoders {best_index}: {outliers}\")\n",
    "\n",
    "        if outliers > OUTLIER_THRESHOLD:\n",
    "            \n",
    "            ###debug###\n",
    "            print(f\"[@ batch {i}] outliers for best autoencoders at index: {best_index} : {outliers}\")\n",
    "            print(f\"[@ batch {i}] NEW autoencoder at {len(auto_list)} for Task: {indicies[0].item()}\")\n",
    "            if indicies[0].item() in record.keys():\n",
    "                print(f\"[@ batch {i}] DUPLICATE autoencoder for Task: {indicies[0].item()}\")\n",
    "            record[indicies[0].item()] = BATCH_SIZE\n",
    "            ###########\n",
    "            \n",
    "            #add new autoencoder\n",
    "            best_autoencoder = Autoencoder(input_dims=28*28, code_dims=CODE_DIM)\n",
    "            for epoch in range(NEW_AUTOENCODER_EPOCH):\n",
    "                best_autoencoder.optimize_params(images, images)\n",
    "            auto_list[len(auto_list)] = best_autoencoder\n",
    "\n",
    "            #add new expert\n",
    "            model = MLP(expert_outdim)\n",
    "            #model = SmallCNN(expert_outdim)\n",
    "            # Train new expert here if required\n",
    "            for _ in range(10):\n",
    "                model.optimizer.zero_grad()\n",
    "                predicted_output = model(images)\n",
    "                fit = model.loss(predicted_output, labels)\n",
    "                fit.backward()\n",
    "                model.optimizer.step()\n",
    "            expert_list[len(auto_list)-1] = model\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            ###debug###\n",
    "            #print(f\"training autoencoder at {best_index} with index: {indicies[0].item()}\")\n",
    "            if not indicies[0].item() in record.keys():\n",
    "                print(f\"[@ batch {i}] outliers for best autoencoders at index: {best_index} : {outliers}\")\n",
    "                print(f\"[@ batch {i}] MISSING autoencoder with Task {indicies[0].item()}\")\n",
    "            else:\n",
    "                record[indicies[0].item()] += BATCH_SIZE\n",
    "            ###########\n",
    "            \n",
    "            #train best autoencoder\n",
    "            for epoch in range(TRAIN_AUTOENCODER_EPOCH):\n",
    "                best_autoencoder.optimize_params(images, images)\n",
    "\n",
    "            #train exsisting expert\n",
    "            model = expert_list[best_index]\n",
    "            # Train new expert here if required\n",
    "            for _ in range(10):\n",
    "                model.optimizer.zero_grad()\n",
    "                predicted_output = model(images)\n",
    "                fit = model.loss(predicted_output, labels)\n",
    "                fit.backward()\n",
    "                model.optimizer.step()\n",
    "\n",
    "        #if i % 100 ==1 :\n",
    "            #best_pred = best_autoencoder.get_prediction(images)\n",
    "            #sample_loss = torch.mean(best_autoencoder.get_unreduced_loss(best_pred, images), dim=1)\n",
    "            #sort_loss, _ = torch.sort(sample_loss, descending=True)\n",
    "            #plt.plot(list(range(sample_loss.shape[0])), sort_loss.cpu().detach().numpy())\n",
    "            #tsplot(sample_loss.cpu().detach().numpy())\n",
    "            #print(record[indicies[0].item()])\n",
    "\n",
    "    print(\"Complete!\")\n",
    "    \n",
    "    ###debug###\n",
    "    #print(expert_list)\n",
    "    ###########\n",
    "    \n",
    "    return auto_list, expert_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4995441-4b6f-4e73-8ad8-8b13003bcad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(test_loader, auto_list, expert_list):\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels, indices in test_loader:\n",
    "            images = images.view(images.shape[0], -1)  # Flatten images\n",
    "            best_index = find_best_autoencoders(images, auto_list)\n",
    "            best_autoencoder = auto_list[best_index]\n",
    "            classifier = expert_list[best_index]\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = classifier(images)\n",
    "            loss = classifier.loss(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f\"Test Loss: {test_loss / len(test_loader)}\")\n",
    "        print(f\"Accuracy: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdacd59b-3f15-4c24-a96e-335f38967cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 300\n",
    "\n",
    "OUTLIER_THRESHOLD = 0.2*BATCH_SIZE\n",
    "NEW_AUTOENCODER_EPOCH = 100\n",
    "TRAIN_AUTOENCODER_EPOCH = 10\n",
    "CODE_DIM = 350\n",
    "\n",
    "NUM_TASK = 10\n",
    "RANDOM_SEED = np.random.randint(100)\n",
    "#RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd1b8d3e-a2f0-4f40-ba56-270b8ad1b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_conbined_permute_mnist(NUM_TASK, BATCH_SIZE, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df4aefd5-f413-4999-8c5d-1b538f1e86ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff7ce9508ec4e8c952537719defdefe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[@ batch 0] NEW autoencoder at 0 for Task 6\n",
      "[@ batch 1] outliers for best autoencoders at index: 0 : 300\n",
      "[@ batch 1] NEW autoencoder at 1 for Task: 4\n",
      "[@ batch 4] outliers for best autoencoders at index: 1 : 300\n",
      "[@ batch 4] NEW autoencoder at 2 for Task: 1\n",
      "[@ batch 5] outliers for best autoencoders at index: 1 : 300\n",
      "[@ batch 5] NEW autoencoder at 3 for Task: 2\n",
      "[@ batch 8] outliers for best autoencoders at index: 3 : 300\n",
      "[@ batch 8] NEW autoencoder at 4 for Task: 0\n",
      "[@ batch 11] outliers for best autoencoders at index: 1 : 300\n",
      "[@ batch 11] NEW autoencoder at 5 for Task: 7\n",
      "[@ batch 12] outliers for best autoencoders at index: 4 : 300\n",
      "[@ batch 12] NEW autoencoder at 6 for Task: 5\n",
      "[@ batch 14] outliers for best autoencoders at index: 1 : 300\n",
      "[@ batch 14] NEW autoencoder at 7 for Task: 9\n",
      "[@ batch 18] outliers for best autoencoders at index: 5 : 298\n",
      "[@ batch 18] NEW autoencoder at 8 for Task: 3\n",
      "[@ batch 21] outliers for best autoencoders at index: 2 : 300\n",
      "[@ batch 21] NEW autoencoder at 9 for Task: 8\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "auto_list, expert_list = train(train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa1fec76-8f93-4779-a3f8-c87aadf4ee2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.45130700755496317\n",
      "Accuracy: 92.785%\n"
     ]
    }
   ],
   "source": [
    "test(test_loader, auto_list, expert_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef4bb148-9d53-4308-b9db-920f96da7756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#unsuccess case due to relatedness of different tasks (e.g. [2, 7] and [3, 1])\n",
    "#BATCH_SIZE = 1000\n",
    "\n",
    "#OUTLIER_THRESHOLD = 0.1*BATCH_SIZE\n",
    "#NEW_AUTOENCODER_EPOCH = 500\n",
    "#TRAIN_AUTOENCODER_EPOCH = 20\n",
    "#CODE_DIM = 350\n",
    "\n",
    "#NUM_TASK = 3\n",
    "#RANDOM_SEED = np.random.randint(100)\n",
    "#RANDOM_SEED = 42\n",
    "\n",
    "#train_loader, test_loader = get_conbined_split_mnist(NUM_TASK, BATCH_SIZE, RANDOM_SEED)\n",
    "\n",
    "#auto_list, expert_list = train(train_loader, 2)\n",
    "\n",
    "#test(test_loader, auto_list, expert_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af1f4a01-8f4a-4f32-952a-c8b3255a642f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 300\n",
    "\n",
    "OUTLIER_THRESHOLD = 0.2*BATCH_SIZE\n",
    "NEW_AUTOENCODER_EPOCH = 100\n",
    "TRAIN_AUTOENCODER_EPOCH = 10\n",
    "CODE_DIM = 500\n",
    "\n",
    "NUM_TASK = 3\n",
    "RANDOM_SEED = np.random.randint(100)\n",
    "#RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0248d8a7-b9bf-41a0-8393-6cbb792cecc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split classes: [[8, 6], [2, 9], [0, 7]]\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, shuffle_idx = get_conbined_splitted_and_shuffled_mnist(NUM_TASK, BATCH_SIZE, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a9d806e-4b72-4b39-8dbb-b41633369b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#MLP classifier, no need to unshuffled\n",
    "#show_image = images[9].cpu().detach().numpy().reshape((28,28))\n",
    "#plt.imshow(show_image) # Plot the 28x28 image\n",
    "#plt.show()\n",
    "\n",
    "#newImage = np.array([0.0]*(784))\n",
    "#show_image = show_image.reshape(-1)\n",
    "#for i,j in enumerate(shuffle_idx):\n",
    "#    newImage[j] = show_image[i]\n",
    "#plt.imshow(newImage.reshape(28,28)) # Plot the 28x28 image\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fee1dbd3-01b2-41ff-8c05-78bb6faf256c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f034a63188744586b4606a2307e5bba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[@ batch 0] NEW autoencoder at 0 for Task 2\n",
      "[@ batch 1] outliers for best autoencoders at index: 0 : 198\n",
      "[@ batch 1] NEW autoencoder at 1 for Task: 0\n",
      "[@ batch 3] outliers for best autoencoders at index: 1 : 87\n",
      "[@ batch 3] NEW autoencoder at 2 for Task: 1\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "auto_list, expert_list = train(train_loader, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bff35df-eb6c-4fd2-ac33-f4532c0326dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.08548424832886212\n",
      "Accuracy: 97.50877779635512%\n"
     ]
    }
   ],
   "source": [
    "test(test_loader, auto_list, expert_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b740660c-291e-4d7f-8bb6-e26963e28266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
