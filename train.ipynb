{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f0140dc6-4050-48ed-bd27-aa8b2018440e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataloader_utils import get_conbined_permute_mnist, get_conbined_split_mnist, get_conbined_permute_and_split_mnist\n",
    "from autoencoder import Autoencoder\n",
    "from autoencoder_utils import * \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3c5739fe-a53c-4055-bcd9-548f5091ad67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    auto_list = {}\n",
    "    expert_list = {}\n",
    "\n",
    "    #debug\n",
    "    record = {}\n",
    "\n",
    "    #https://stats.stackexchange.com/questions/521461/train-a-model-on-batches-with-multiple-epochs-vs-each-batch-with-multiple-epoch\n",
    "    #for i, data in enumerate(train_loader):\n",
    "    for i, data in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        images, labels, indicies = data\n",
    "        \n",
    "        #debug\n",
    "        #show_image = images[0].cpu().detach().numpy().reshape((28,28))\n",
    "        #plt.imshow(show_image) # Plot the 28x28 image\n",
    "        #plt.show()\n",
    "        \n",
    "        #initial \n",
    "        if len(auto_list)==0:\n",
    "            #debug\n",
    "            print(f\"[@ batch {i}] NEW autoencoder at {len(auto_list)} for Task {indicies[0].item()}\")\n",
    "            record[len(auto_list)] = indicies[0].item()\n",
    "\n",
    "            #initial autoencoder\n",
    "            new_autoencoder = Autoencoder(input_dims=28*28, code_dims=CODE_DIM)\n",
    "            for epoch in range(NEW_AUTOENCODER_EPOCH):\n",
    "                new_autoencoder.optimize_params(images, images)\n",
    "            auto_list[len(auto_list)] = new_autoencoder\n",
    "\n",
    "            #to-do add initial expert\n",
    "            expert_list[len(auto_list)-1] = BATCH_SIZE\n",
    "            continue\n",
    "\n",
    "        #find best autoencoder\n",
    "        best_index = find_best_autoencoders(images, auto_list)\n",
    "        best_autoencoder = auto_list[best_index]\n",
    "\n",
    "\n",
    "        #calculate outliers\n",
    "        outliers = find_num_of_outliers(images, best_autoencoder)\n",
    "        #print(f\"[@ batch {i}] outliers for best autoencoders {best_index}: {outliers}\")\n",
    "\n",
    "        if outliers > OUTLIER_THRESHOLD:\n",
    "            #debug\n",
    "            print(f\"[@ batch {i}] outliers for best autoencoders at index: {best_index} : {outliers}\")\n",
    "            print(f\"[@ batch {i}] NEW autoencoder at {len(auto_list)} for Task: {indicies[0].item()}\")\n",
    "            if indicies[0].item() in record.values():\n",
    "                print(f\"[@ batch {i}] DUPLICATE autoencoder for Task: {indicies[0].item()}\")\n",
    "                record[len(auto_list)] = indicies[0].item()\n",
    "            else:\n",
    "                record[len(auto_list)] = indicies[0].item()\n",
    "\n",
    "            #add new autoencoder\n",
    "            best_autoencoder = Autoencoder(input_dims=28*28, code_dims=CODE_DIM)\n",
    "            for epoch in range(NEW_AUTOENCODER_EPOCH):\n",
    "                best_autoencoder.optimize_params(images, images)\n",
    "            auto_list[len(auto_list)] = best_autoencoder\n",
    "\n",
    "            #to-do add new expert\n",
    "            expert_list[len(auto_list)-1] = BATCH_SIZE\n",
    "            \n",
    "        else:\n",
    "            #debug\n",
    "            #print(f\"training autoencoder at {best_index} with index: {indicies[0].item()}\")\n",
    "            if not indicies[0].item() in record.values():\n",
    "                print(f\"[@ batch {i}] outliers for best autoencoders at index: {best_index} : {outliers}\")\n",
    "                print(f\"[@ batch {i}] MISSING autoencoder with Task {indicies[0].item()}\")\n",
    "                continue\n",
    "                \n",
    "            #train best autoencoder\n",
    "            for epoch in range(TRAIN_AUTOENCODER_EPOCH):\n",
    "                best_autoencoder.optimize_params(images, images)\n",
    "\n",
    "            #to-do train exsisting expert\n",
    "            expert_list[best_index] += BATCH_SIZE\n",
    "\n",
    "        if i % (len(train_loader)/20) ==0 :\n",
    "            print(expert_list)\n",
    "            \n",
    "    print(\"Complete!\")\n",
    "    \n",
    "    #debug\n",
    "    print(expert_list)\n",
    "    \n",
    "    return auto_list, expert_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bdacd59b-3f15-4c24-a96e-335f38967cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 300\n",
    "\n",
    "OUTLIER_THRESHOLD = 0.2*BATCH_SIZE\n",
    "NEW_AUTOENCODER_EPOCH = 100\n",
    "TRAIN_AUTOENCODER_EPOCH = 10\n",
    "CODE_DIM = 350\n",
    "\n",
    "NUM_TASK = 10\n",
    "RANDOM_SEED = np.random.randint(100)\n",
    "#RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dd1b8d3e-a2f0-4f40-ba56-270b8ad1b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_conbined_permute_mnist(NUM_TASK, BATCH_SIZE, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "df4aefd5-f413-4999-8c5d-1b538f1e86ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f446ff0628404a1d85b371cd0f90e5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[@ batch 0] NEW autoencoder at 0 for Task 9\n",
      "[@ batch 1] outliers for best autoencoders at index: 0 : 300\n",
      "[@ batch 1] NEW autoencoder at 1 for Task: 0\n",
      "[@ batch 2] outliers for best autoencoders at index: 0 : 300\n",
      "[@ batch 2] NEW autoencoder at 2 for Task: 8\n",
      "[@ batch 3] outliers for best autoencoders at index: 0 : 300\n",
      "[@ batch 3] NEW autoencoder at 3 for Task: 5\n",
      "[@ batch 5] outliers for best autoencoders at index: 2 : 300\n",
      "[@ batch 5] NEW autoencoder at 4 for Task: 6\n",
      "[@ batch 8] outliers for best autoencoders at index: 2 : 300\n",
      "[@ batch 8] NEW autoencoder at 5 for Task: 4\n",
      "[@ batch 10] outliers for best autoencoders at index: 4 : 300\n",
      "[@ batch 10] NEW autoencoder at 6 for Task: 7\n",
      "[@ batch 11] outliers for best autoencoders at index: 4 : 300\n",
      "[@ batch 11] NEW autoencoder at 7 for Task: 1\n",
      "[@ batch 14] outliers for best autoencoders at index: 0 : 300\n",
      "[@ batch 14] NEW autoencoder at 8 for Task: 3\n",
      "[@ batch 21] outliers for best autoencoders at index: 6 : 300\n",
      "[@ batch 21] NEW autoencoder at 9 for Task: 2\n",
      "{0: 4500, 1: 3900, 2: 2700, 3: 3000, 4: 3300, 5: 2100, 6: 2100, 7: 2100, 8: 3900, 9: 2700}\n",
      "{0: 5700, 1: 7800, 2: 6900, 3: 6000, 4: 6000, 5: 4500, 6: 4200, 7: 5400, 8: 6900, 9: 6900}\n",
      "{0: 8700, 1: 10500, 2: 10800, 3: 9000, 4: 9300, 5: 6900, 6: 7200, 7: 8700, 8: 9900, 9: 9300}\n",
      "{0: 11700, 1: 14400, 2: 13500, 3: 11700, 4: 12000, 5: 10800, 6: 9300, 7: 11400, 8: 12300, 9: 13200}\n",
      "{0: 14100, 1: 16800, 2: 17100, 3: 13800, 4: 14100, 5: 15900, 6: 12600, 7: 14100, 8: 15600, 9: 16200}\n",
      "{0: 17400, 1: 20100, 2: 19200, 3: 16500, 4: 16200, 5: 19500, 6: 16500, 7: 16500, 8: 18600, 9: 19800}\n",
      "{0: 20700, 1: 22200, 2: 21600, 3: 19500, 4: 18000, 5: 22800, 6: 19500, 7: 19800, 8: 23400, 9: 22800}\n",
      "{0: 22500, 1: 24600, 2: 24600, 3: 23100, 4: 21300, 5: 25500, 6: 22800, 7: 23100, 8: 27900, 9: 24900}\n",
      "{0: 26700, 1: 26100, 2: 27900, 3: 25200, 4: 23100, 5: 29700, 6: 26700, 7: 25200, 8: 31800, 9: 27900}\n",
      "{0: 28800, 1: 28500, 2: 31800, 3: 28200, 4: 27300, 5: 31500, 6: 29100, 7: 28500, 8: 36000, 9: 30600}\n",
      "{0: 32100, 1: 31200, 2: 34800, 3: 32100, 4: 30000, 5: 33600, 6: 31500, 7: 31800, 8: 38100, 9: 35100}\n",
      "{0: 35100, 1: 34500, 2: 36000, 3: 35700, 4: 33900, 5: 37800, 6: 33600, 7: 36300, 8: 39600, 9: 37800}\n",
      "{0: 38100, 1: 37800, 2: 39900, 3: 39000, 4: 37800, 5: 40800, 6: 36900, 7: 39000, 8: 41100, 9: 39900}\n",
      "{0: 42600, 1: 40800, 2: 43200, 3: 41700, 4: 39900, 5: 43800, 6: 39600, 7: 42300, 8: 42900, 9: 43500}\n",
      "{0: 45600, 1: 43500, 2: 45900, 3: 45000, 4: 43200, 5: 47700, 6: 42900, 7: 44700, 8: 44700, 9: 47100}\n",
      "{0: 47100, 1: 45600, 2: 48900, 3: 48300, 4: 46500, 5: 49800, 6: 47700, 7: 48300, 8: 48600, 9: 49500}\n",
      "{0: 51300, 1: 49500, 2: 51300, 3: 51300, 4: 49500, 5: 52500, 6: 51300, 7: 51000, 8: 51900, 9: 50700}\n",
      "{0: 54600, 1: 52200, 2: 55500, 3: 54300, 4: 54300, 5: 55200, 6: 53700, 7: 52800, 8: 54300, 9: 53400}\n",
      "{0: 57300, 1: 55800, 2: 57900, 3: 57000, 4: 56400, 5: 58500, 6: 57600, 7: 55800, 8: 57300, 9: 56700}\n",
      "Complete!\n",
      "{0: 60000, 1: 60000, 2: 60000, 3: 60000, 4: 60000, 5: 60000, 6: 60000, 7: 60000, 8: 60000, 9: 60000}\n"
     ]
    }
   ],
   "source": [
    "auto_list, expert_list = train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4bb148-9d53-4308-b9db-920f96da7756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#unsuccess case due to relatedness of different tasks (e.g. [2, 7] and [3, 1])\n",
    "#BATCH_SIZE = 1000\n",
    "\n",
    "#OUTLIER_THRESHOLD = 0.1*BATCH_SIZE\n",
    "#NEW_AUTOENCODER_EPOCH = 500\n",
    "#TRAIN_AUTOENCODER_EPOCH = 20\n",
    "#CODE_DIM = 350\n",
    "\n",
    "#NUM_TASK = 5\n",
    "#RANDOM_SEED = np.random.randint(100)\n",
    "#RANDOM_SEED = 42\n",
    "\n",
    "#train_loader, test_loader = get_conbined_split_mnist(NUM_TASK, BATCH_SIZE, RANDOM_SEED)\n",
    "\n",
    "#auto_list, expert_list = train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "af1f4a01-8f4a-4f32-952a-c8b3255a642f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000\n",
    "\n",
    "OUTLIER_THRESHOLD = 0.1*BATCH_SIZE\n",
    "NEW_AUTOENCODER_EPOCH = 200\n",
    "TRAIN_AUTOENCODER_EPOCH = 20\n",
    "CODE_DIM = 350\n",
    "\n",
    "NUM_TASK = 4\n",
    "RANDOM_SEED = np.random.randint(100)\n",
    "#RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0248d8a7-b9bf-41a0-8393-6cbb792cecc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split classes: [[3, 2], [9, 0], [1, 6], [7, 5]]\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_conbined_permute_and_split_mnist(NUM_TASK, BATCH_SIZE, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fee1dbd3-01b2-41ff-8c05-78bb6faf256c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f185b44fa7d403a8867529aef10ee88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[@ batch 0] NEW autoencoder at 0 for Task 3\n",
      "[@ batch 1] outliers for best autoencoders at index: 0 : 466\n",
      "[@ batch 1] NEW autoencoder at 1 for Task: 1\n",
      "[@ batch 4] outliers for best autoencoders at index: 0 : 175\n",
      "[@ batch 4] NEW autoencoder at 2 for Task: 2\n",
      "[@ batch 5] outliers for best autoencoders at index: 0 : 123\n",
      "[@ batch 5] NEW autoencoder at 3 for Task: 2\n",
      "[@ batch 5] DUPLICATE autoencoder for Task: 2\n",
      "[@ batch 6] outliers for best autoencoders at index: 0 : 447\n",
      "[@ batch 6] NEW autoencoder at 4 for Task: 0\n",
      "Complete!\n",
      "{0: 12000, 1: 12000, 2: 1000, 3: 12000, 4: 12000}\n"
     ]
    }
   ],
   "source": [
    "auto_list, expert_list = train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bff35df-eb6c-4fd2-ac33-f4532c0326dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
